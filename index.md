---
layout: homepage
---

I am a Ph.D. Candidate at the [University of Rochester](https://www.cs.rochester.edu/), working with [Jiebo Luo](https://www.cs.rochester.edu/u/jluo/) on computer vision and machine learning. My research focuses on visual generation and editing, bridging the gap between human creativity and computational intelligence.

<div class="pub-stats">
  <div class="pub-stats-inner">
    <div class="stat-item">
      <div class="stat-num">1</div>
      <div class="stat-desc">ICCV <strong>first‑author</strong> papers</div>
    </div>
    <div class="stat-divider" aria-hidden="true"></div>
    <div class="stat-item">
      <div class="stat-num">1</div>
      <div class="stat-desc">NeurIPS <strong>first‑author</strong> papers</div>
    </div>
    <div class="stat-divider" aria-hidden="true"></div>
    <div class="stat-item">
      <div class="stat-num">2</div>
      <div class="stat-desc">ECCV <strong>first‑author</strong> papers</div>
    </div>
    <div class="stat-divider" aria-hidden="true"></div>
    <div class="stat-item">
      <div class="stat-num">2</div>
      <div class="stat-desc">ICLR / IJCV <strong>co‑first</strong> papers</div>
    </div>
  </div>
  <div class="pub-stats-note">Publication counts by top-tier venues.</div>
</div>

## News

<div class="news-item">
<div class="news-date">06/2025</div>
<div class="news-content"><a href="https://arxiv.org/abs/2503.08677">OmniPaint</a> is accepted to <a href="https://iccv.thecvf.com/">ICCV 2025</a>.</div>
</div>


<div class="news-item">
<div class="news-date">04/2025</div>
<div class="news-content">32×-compressed latent SR model <a href="https://arxiv.org/pdf/2504.08591">ZipIR</a> report is available! (Completed Nov 2024, delayed release due to patent application)</div>
</div>

<div class="news-item">
<div class="news-date">02/2025</div>
<div class="news-content">Joining <a href="https://www.nvidia.com/en-us/">NVIDIA</a> as a Research Intern this summer.</div>
</div>

<div class="news-item">
<div class="news-date">09/2024</div>
<div class="news-content"><a href="https://arxiv.org/abs/2405.16785">PromptFix</a> is accepted to <a href="https://neurips.cc/Conferences/2024">NeurIPS 2024</a>.</div>
</div>

<div class="news-item">
<div class="news-date">01/2024</div>
<div class="news-content">Our MaGIC is accepted to <a href="https://iclr.cc/">ICLR 2024</a>.</div>
</div>

<!-- <div class="news-item">
<div class="news-date">07/2022</div>
<div class="news-content">Two papers accepted to <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.</div>
</div> -->

## Experience

<div class="experience-item">
<div class="exp-header">
<div class="exp-title"><a href="https://www.nvidia.com/en-us/">NVIDIA</a></div>
<div class="exp-duration">May 2025 - Present</div>
</div>
<div class="exp-role">Research Intern</div>
<div class="exp-location">Santa Clara, US</div>
</div>

<div class="experience-item">
<div class="exp-header">
<div class="exp-title"><a href="https://research.adobe.com/">Adobe Research</a></div>
<div class="exp-duration">May 2024 - April 2025</div>
</div>
<div class="exp-role">Research Intern</div>
<div class="exp-location">San Jose, US</div>
</div>

<div class="experience-item">
<div class="exp-header">
<div class="exp-title"><a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a></div>
<div class="exp-duration">May 2023 - August 2023</div>
</div>
<div class="exp-role">Research Intern</div>
<div class="exp-location">Beijing, China</div>
</div>

## Publications

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2025/03/13/CD58aw3gRuXzjIK.gif" alt="OmniPaint">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2503.08677">OmniPaint: Mastering Object-Oriented Editing via Disentangled Insertion-Removal Inpainting</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>*, Ziyun Zeng*, Haitian Zheng, Jiebo Luo</div>
<div class="pub-venue">ICCV, 2025 <a href="https://github.com/yeates/OmniPaint"><img src="https://img.shields.io/github/stars/yeates/OmniPaint?style=social" alt="GitHub stars" style="vertical-align: middle; margin-left: 10px;"></a></div>
<div class="pub-links">
<a href="https://www.yongshengyu.com/OmniPaint-Page/">Project</a>
<a href="https://arxiv.org/pdf/2503.08677">PDF</a>
<a href="https://github.com/yeates/OmniPaint">Code</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2025/04/14/1TYjHhpcwQ7u2vF.jpg" alt="ZipIR">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2504.08591">ZipIR: Latent Pyramid Diffusion Transformer for High-Resolution Image Restoration</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>, Haitian Zheng, Zhifei Zhang, Jianming Zhang, Yuqian Zhou, Connelly Barnes, Yuchen Liu, Wei Xiong, Zhe Lin, Jiebo Luo</div>
<div class="pub-venue">In submission, 2025</div>
<div class="pub-links">
<a href="https://arxiv.org/pdf/2504.08591">PDF</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2024/10/04/e7wQchYHOFEJ3ZD.gif" alt="PromptFix">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2405.16785">PromptFix: You Prompt and We Fix the Photo</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>*, Ziyun Zeng*, Hang Hua, Jianlong Fu, Jiebo Luo</div>
<div class="pub-venue">NeurIPS, 2024 <a href="https://github.com/yeates/PromptFix"><img src="https://img.shields.io/github/stars/yeates/PromptFix?style=social" alt="GitHub stars" style="vertical-align: middle; margin-left: 10px;"></a></div>
<div class="pub-links">
<a href="https://www.yongshengyu.com/PromptFix-Page/">Project</a>
<a href="https://arxiv.org/pdf/2405.16785">PDF</a>
<a href="https://github.com/yeates/PromptFix">Code</a>
<a href="https://huggingface.co/datasets/yeates/PromptfixData">Dataset</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2023/11/25/V91f7PYqSwoaJmK.png" alt="MaGIC">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2305.11818">MaGIC: Multi-modality Guided Image Completion</a></div>
<div class="pub-authors">Hao Wang*, <strong>Yongsheng Yu</strong>*, Tiejian Luo, Heng Fan, Libo Zhang</div>
<div class="pub-venue">ICLR, 2024</div>
<div class="pub-links">
<a href="https://arxiv.org/pdf/2305.11818.pdf">PDF</a>
<a href="https://yeates.github.io/MaGIC-Page">Website</a>
<a href="https://github.com/yeates/MaGIC">Code</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2023/11/25/eiIWXha2vrsfVyk.gif" alt="DMT">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2307.08629">Deficiency-Aware Masked Transformer for Video Inpainting</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>, Heng Fan, Libo Zhang, Jiebo Luo</div>
<div class="pub-venue">In Submission, 2023</div>
<div class="pub-links">
<a href="https://arxiv.org/pdf/2307.08629.pdf">PDF</a>
<a href="https://github.com/yeates/DMT">Code</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2024/07/23/TXJhvWRS5xBo29L.jpg" alt="Chain-of-Thought">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/pdf/2405.15687">Chain-of-Thought Prompting for Demographic Inference with Large Multimodal Models</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>, Jiebo Luo</div>
<div class="pub-venue">ICME (Oral), 2024</div>
<div class="pub-links">
<a href="https://arxiv.org/pdf/2405.15687">PDF</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2022/07/26/P87oHlKk1tNDxrG.png" alt="Unbiased Multi-Modality">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2208.11844">Unbiased Multi-Modality Guidance for Image Inpainting</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>, Dawei Du, Libo Zhang, Tiejian Luo</div>
<div class="pub-venue">ECCV, 2022</div>
<div class="pub-links">
<a href="https://arxiv.org/abs/2208.11844">PDF</a>
<a href="https://github.com/yeates/MMT">Code</a>
</div>
</div>
</div>
</div>

<div class="publication-item">
<div class="pub-row">
<div class="pub-image">
<img src="https://s2.loli.net/2022/07/26/Ppk4TmYCqyvf7Zl.png" alt="High-Fidelity Inpainting">
</div>
<div class="pub-content">
<div class="pub-title"><a href="https://arxiv.org/abs/2208.11850">High-Fidelity Image Inpainting with GAN Inversion</a></div>
<div class="pub-authors"><strong>Yongsheng Yu</strong>, Libo Zhang, Heng Fan, Tiejian Luo</div>
<div class="pub-venue">ECCV, 2022</div>
<div class="pub-links">
<a href="https://arxiv.org/abs/2208.11850">PDF</a>
</div>
</div>
</div>
</div>
## Services

Reviewer:
- 2025: CVPR, ICCV, ICLR, MM, NeurIPS, AAAI, TIP
- 2024: CVPR, ECCV, ICML, ICLR, ICME, MM, NeurIPS, WACV
- 2023: CVPR, ICCV, NeurIPS, WACV

<br>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=250&t=n&d=RoDpcfB2vG1lN_1So1H7EOpCNMohRUZg7CEirev-baw&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>

<p style="text-align: center"><small>Powered by Jekyll</small></p>